{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-transfer-example-iops.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4y4W021Dtt+xMHMYAHiw4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grantthomas/iops_resources/blob/master/demos/Keras_transfer_example_iops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ234d5gQI-J"
      },
      "source": [
        "\n",
        "#!wget https://github.com/grantthomas/iops_resources/raw/master/keras-transfer-files/downloads.zip\n",
        "#!unzip -n downloads.zip\n",
        "\n",
        "#!wget https://github.com/grantthomas/iops_resources/raw/master/images/autolevel-small.zip\n",
        "#!unzip -n autolevel-small.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtkwepMTQp3g"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "from keras.optimizers import Adam\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFNcOwacQxRV"
      },
      "source": [
        "\n",
        "mobile = keras.applications.mobilenet.MobileNet()\n",
        "def prepare_image(file):\n",
        "    img_path = ''\n",
        "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5FJ5bGhXJ9I",
        "outputId": "24752727-c1c1-4794-fd12-e4dffdc4b34e"
      },
      "source": [
        "\n",
        "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(2,activation='softmax')(x) #final layer with softmax activation"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbChjOI9XOen"
      },
      "source": [
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)\n",
        "#specify the inputs\n",
        "#specify the outputs\n",
        "#now a model has been created based on our architecture"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV2TPo2hXRr2"
      },
      "source": [
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable=True\n",
        "# or if we want to set the first 20 layers of the network to be non-trainable\n",
        "#for layer in model.layers[:20]:\n",
        "    #layer.trainable=False\n",
        "#for layer in model.layers[20:]:\n",
        "    #layer.trainable=True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jic_tM2XUHR",
        "outputId": "9ad47feb-3587-465a-bc9b-94ca960b5080"
      },
      "source": [
        "\n",
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory('./autolevel-small/train',\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh0v1G87XdM1"
      },
      "source": [
        "\n",
        "def load_image(img_path, show=False):\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "    if show:\n",
        "        plt.imshow(img_tensor[0])                           \n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return img_tensor\n",
        "  \n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtAmxaH1XYIw",
        "outputId": "d49d52fb-d409-4e2a-e9c2-23d6e3c44500"
      },
      "source": [
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-1d4221ccfbd2>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            " 2/25 [=>............................] - ETA: 2s - loss: 0.7501 - accuracy: 0.7031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0434s vs `on_train_batch_end` time: 0.1435s). Check your callbacks.\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.4111 - accuracy: 0.9075\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0225 - accuracy: 0.9950\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0103 - accuracy: 0.9975\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0164 - accuracy: 0.9975\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0112 - accuracy: 0.9987\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0541 - accuracy: 0.9962\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0113 - accuracy: 0.9962\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0093 - accuracy: 0.9975\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0057 - accuracy: 0.9987\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0040 - accuracy: 0.9987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f60883adf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irrjxzgnYRSY",
        "outputId": "62bafecd-a358-4509-e4b7-f709953c5fa7"
      },
      "source": [
        "img_path = './autolevel-small/test/false/camera-36_2020-10-25_21-45_to_2020-10-25_21-57.mp40661.jpg'\n",
        "#expect [100, 0]\n",
        "new_image = load_image(img_path)\n",
        "\n",
        "pred = model.predict(new_image)\n",
        "\n",
        "if (pred[0][0] > pred[0][1]):\n",
        "  print(\"Eval: False\")\n",
        "else:\n",
        "  print(\"Eval: True\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eval: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5AwFS_rYZnQ",
        "outputId": "c63f246e-0f89-4351-b680-1e52ed61f2e1"
      },
      "source": [
        "img_path = './autolevel-small/test/true/camera-41_2020-11-01_16-44_to_2020-11-01_16-56.mp40182.jpg'\n",
        "#expect [0, 100]\n",
        "\n",
        "new_image = load_image(img_path)\n",
        "\n",
        "pred = model.predict(new_image)\n",
        "\n",
        "if (pred[0][0] > pred[0][1]):\n",
        "  print(\"Eval: False\")\n",
        "else:\n",
        "  print(\"Eval: True\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eval: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UkwfZ9XMNdL",
        "outputId": "f3df4ed2-05cc-4ef6-961e-d41031f9368d"
      },
      "source": [
        "img_path = './spirit-test-true.jpg'\n",
        "#expect [0, 100]\n",
        "\n",
        "new_image = load_image(img_path)\n",
        "\n",
        "pred = model.predict(new_image)\n",
        "\n",
        "if (pred[0][0] > pred[0][1]):\n",
        "  print(\"Eval: False\")\n",
        "else:\n",
        "  print(\"Eval: True\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eval: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnwjFjItLU9j"
      },
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('./model', exist_ok=True)\n",
        "\n",
        "model.save(\"./model/model.h5\")"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}